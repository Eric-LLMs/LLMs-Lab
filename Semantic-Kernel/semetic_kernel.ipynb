{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3110c8a35a023104",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 1. Hello, World! \n",
    "## 1.1 This is a simple demo\n",
    "The first block of code is initialization. All subsequent code must be executed after this block has been run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288670bb54a28795",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:40:49.556312Z",
     "start_time": "2024-09-18T10:40:49.539852600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# pip install semantic-kernel==0.9.6b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8487d2dfd3108d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:40:50.126365200Z",
     "start_time": "2024-09-18T10:40:50.086222900Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:26:48.033410Z",
     "start_time": "2024-09-19T06:26:47.964172700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "# Load .env into environment variables\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Create semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Configure OpenAI service. OPENAI_BASE_URL will be automatically loaded and applied\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "service_id = \"default\"\n",
    "service = OpenAIChatCompletion(\n",
    "    service_id=service_id,\n",
    "    ai_model_id=\"gpt-3.5-turbo-1106\",\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# Add the LLM service to the kernel\n",
    "# Multiple services can be added. The first added will be used by default, non-default ones must be specified to use\n",
    "kernel.add_service(service)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fe0f0875434e9",
   "metadata": {},
   "source": [
    "Prompt calls a large model, which is treated as a Semantic Function (detailed below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff334b0b155ec9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:26:51.659383600Z",
     "start_time": "2024-09-19T06:26:50.732949400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't skeletons fight each other?\n",
      "\n",
      "They don't have the guts!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "# Define semantic function\n",
    "joke_function = kernel.add_function(\n",
    "    function_name='joke',  # Function name, required\n",
    "    plugin_name=\"MyDemoPlugin\",  # Plugin the function belongs to, required\n",
    "    prompt=\"Tell a joke\"  # Prompt, required\n",
    ")\n",
    "\n",
    "# Run the function and check the result\n",
    "result = await kernel.invoke(joke_function)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27a3ab2c42743c",
   "metadata": {},
   "source": [
    "The above code is executed in the form of a Jupyter notebook. If running locally, please refer to the following format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74ee03caf40d9d69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:41:03.152700800Z",
     "start_time": "2024-09-18T10:41:03.145338700Z"
    }
   },
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# \n",
    "# async def run_function(*args):\n",
    "#     return await kernel.invoke(*args)\n",
    "# \n",
    "# result = asyncio.run(\n",
    "#     run_function(joke_function)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce36f4-99f4-4eb8-99b3-7c5bbb685262",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Key Points:</b>\n",
    "Using an analogy with the operating system we're familiar with can help better understand SK.\n",
    "<ol>\n",
    "<li>Start the operating system: <code>kernel = sk.Kernel()</code></li>\n",
    "<li>Install drivers: <code>kernel.add_xxx_service()</code></li>\n",
    "<li>Install applications: <code>func = kernel.create_semantic_function()</code></li>\n",
    "<li>Run applications: <code>kernel.invoke(func...)</code></li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368022f60fb51b3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<div class=\"alert white-background\" style=\"background-color: white; color: black; padding: 10px;\">\n",
    "    The following diagram shows the basic architecture of SK.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603170c0e3a52d7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1.2 Overview \n",
    "\n",
    "#### Mind-and-Body-of-Semantic-Kernel:\n",
    "\n",
    "<img src=\"data/mind-and-body-of-semantic-kernel.png\" style=\"margin-left: 0px\" width=500px>\n",
    "\n",
    "\n",
    "#### Plugins:\n",
    "##### Review the design concepts of microservices: Applications use SK to call Plugins to complete various tasks.\n",
    "<img src=\"data/plugins.png\" style=\"margin-left: 0px\" width=700px>\n",
    "\n",
    "#### Kernel:\n",
    "\n",
    "<img src=\"data/kernel.png\" style=\"margin-left: 0px\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3053d696-97f2-4266-85e8-d64f0026401d",
   "metadata": {},
   "source": [
    "# 2. Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08d37ac4-972a-4752-8c06-a657ca669903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:41:10.623923Z",
     "start_time": "2024-09-18T10:41:10.606893300Z"
    }
   },
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template.prompt_template_config import PromptTemplateConfig\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "# Get the default settings\n",
    "reg_settings = kernel.get_service(service_id).get_prompt_execution_settings_class()(service_id=service_id)\n",
    "\n",
    "# Define the Prompt template\n",
    "# In the template, variables are represented as {$topic}\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=\"Tell a joke about {{$topic}}\",\n",
    "    description=\"Generate a joke about a specific topic\",\n",
    "    execution_settings={service_id: reg_settings},\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"topic\", description=\"The topic\", is_required=True)\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Register the function\n",
    "topical_joke_function = kernel.add_function(\n",
    "    function_name=\"topic_joke\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d61e760959c97fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:41:17.831461800Z",
     "start_time": "2024-09-18T10:41:14.028870400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did Eric bring a ladder to the bar?\n",
      "\n",
      "Because he heard the drinks were on the house!\n"
     ]
    }
   ],
   "source": [
    "# Run the function and get the result\n",
    "result = await kernel.invoke(\n",
    "    topical_joke_function,\n",
    "    KernelArguments(topic=\"Eric\") # 传入参数\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19997e81ec025c78",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 3. Semantic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d5d08ae70e7f334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:41:23.613610Z",
     "start_time": "2024-09-18T10:41:22.195481700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM Courses WHERE course_date BETWEEN '2024-04-01' AND '2024-04-30';\n"
     ]
    }
   ],
   "source": [
    "# Load semantic function. Pay attention to the directory structure\n",
    "my_plugins = kernel.add_plugin(parent_directory=\"./demo\", plugin_name=\"MyPlugins\")\n",
    "\n",
    "func = my_plugins[\"Text2SQL\"]\n",
    "\n",
    "# Execute\n",
    "result = await kernel.invoke(\n",
    "    func,\n",
    "    KernelArguments(input=\"What courses are available in April 2024\"),\n",
    ")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324107247e00d8c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3.1 Multiple Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511260e381c98ce1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:41:29.825487700Z",
     "start_time": "2024-09-18T10:41:29.804883100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Conversation history is as follows:\n",
    "{{ $history }}\n",
    "---\n",
    "User: {{ $request }}\n",
    "Assistant: \"\"\"\n",
    "# Define Prompt Template\n",
    "# In the template, variables are represented as {{ variable_name }}\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    description=\"Multi-turn dialogue\",\n",
    "    execution_settings={service_id: reg_settings},\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"request\", description=\"The user input\", is_required=True),\n",
    "        InputVariable(name=\"history\", description=\"The dialogue history\", is_required=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Register function\n",
    "chat = kernel.add_function(\n",
    "    function_name=\"chat\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96846675814cea8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:42:21.040507100Z",
     "start_time": "2024-09-18T10:41:32.276785Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello, Eric! How can I assist you today?\n",
      "Assistant: As an AI, I don't have feelings, but I'm here and ready to help you with any questions or concerns you may have. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_system_message(\"You are a helpful chatbot who is good at answering users' questions.\")\n",
    "\n",
    "while True:\n",
    "    request = input('User: ').strip()\n",
    "    if not request:\n",
    "        break\n",
    "    result = await kernel.invoke(\n",
    "        chat,\n",
    "        KernelArguments(\n",
    "        request=request,\n",
    "        history=chat_history\n",
    "        ),\n",
    "    )\n",
    "    print(f'Assistant: {result}')\n",
    "    chat_history.add_user_message(request)\n",
    "    chat_history.add_assistant_message(str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ee8975faead91",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3.2 Native Funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "379c019c50f24ba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:42:26.622131100Z",
     "start_time": "2024-09-18T10:42:26.607064800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from semantic_kernel.functions  import kernel_function\n",
    "\n",
    "\n",
    "class DBConnectorPlugin:\n",
    "    def __init__(self, db_cursor):\n",
    "        self.db_cursor = db_cursor\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"查询数据库\", # function description\n",
    "        name=\"query_database\", # function name\n",
    "    )\n",
    "    def exec(self, sql_exp: str) -> str:\n",
    "        self.db_cursor.execute(sql_exp)\n",
    "        records = cursor.fetchall()\n",
    "        return str(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b121fb5cbbefd912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:42:36.727704400Z",
     "start_time": "2024-09-18T10:42:36.717678400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define native data and SQL DB \n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# creat connection of DB\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# create table\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE Courses (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    course_date DATE NOT NULL,\n",
    "    start_time TIME NOT NULL,\n",
    "    end_time TIME NOT NULL,\n",
    "    course_name VARCHAR(255) NOT NULL,\n",
    "    instructor VARCHAR(255) NOT NULL\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Insert 5 specific sample records\n",
    "timetable = [\n",
    "    ('2024-01-23', '20:00', '22:00', 'Basics of English Writing', 'John'),\n",
    "    ('2024-01-25', '20:00', '22:00', 'Advanced English Grammar', 'John'),\n",
    "    ('2024-01-29', '20:00', '22:00', 'English Literature: An Introduction', 'Mary'),\n",
    "    ('2024-02-20', '20:00', '22:00', 'Conversational English', 'David'),\n",
    "    ('2024-02-22', '20:00', '22:00', 'English for Business Communication', 'John'),\n",
    "    ('2024-02-29', '20:00', '22:00', 'Public Speaking and Presentation Skills', 'Alice'),\n",
    "    ('2024-03-05', '20:00', '22:00', 'English Phonetics and Phonology', 'Alice'),\n",
    "    ('2024-03-07', '20:00', '22:00', 'Creative Writing', 'Alice'),\n",
    "    ('2024-03-14', '20:00', '22:00', 'Preparation for TOEFL', 'Alice'),\n",
    "    ('2024-03-19', '20:00', '22:00', 'English Vocabulary Building', 'Alice'),\n",
    "    ('2024-03-21', '20:00', '22:00', 'English for Academic Purposes', 'Alice'),\n",
    "    ('2024-03-26', '20:00', '22:00', 'Reading Comprehension Techniques (Part 1)', 'Alice'),\n",
    "    ('2024-03-28', '20:00', '22:00', 'Reading Comprehension Techniques (Part 2)', 'Alice'),\n",
    "    ('2024-04-09', '20:00', '22:00', 'Understanding English Idioms (Part 1)', 'Mark'),\n",
    "    ('2024-04-11', '20:00', '22:00', 'Understanding English Idioms (Part 2)', 'Mark'),\n",
    "    ('2024-04-16', '20:00', '22:00', 'Understanding English Idioms (Part 3)', 'Mark'),\n",
    "    ('2024-04-18', '20:00', '22:00', 'English for Travel (Part 1)', 'Sophia'),\n",
    "    ('2024-04-23', '20:00', '22:00', 'English for Travel (Part 2)', 'Sophia'),\n",
    "    ('2024-04-25', '20:00', '22:00', 'Career Opportunities in English Language', 'John'),\n",
    "    ('2024-05-07', '20:00', '22:00', 'English for Customer Service', 'John'),\n",
    "    ('2024-05-09', '20:00', '22:00', 'Introduction to English Linguistics', 'John'),\n",
    "    ('2024-05-14', '20:00', '22:00', 'English for Project Management', 'Alice'),\n",
    "]\n",
    "\n",
    "for record in timetable:\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Courses (course_date, start_time, end_time, course_name, instructor)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    ''', record)\n",
    "\n",
    "# Commit the transaction\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98dec15b59280d00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:42:39.793166300Z",
     "start_time": "2024-09-18T10:42:39.747584600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9,)]\n"
     ]
    }
   ],
   "source": [
    "# load native function\n",
    "db_connector = kernel.add_plugin(DBConnectorPlugin(cursor), \"DBConnectorPlugin\")\n",
    "\n",
    "# return the result\n",
    "result = await kernel.invoke(\n",
    "    db_connector[\"query_database\"],\n",
    "    KernelArguments(\n",
    "        sql_exp=\"SELECT COUNT(*) as count FROM Courses WHERE instructor = 'Alice'\"\n",
    "    ),\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5b1314da410a6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "another native function method is as following  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c1b12ea8b087ccb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:42:42.777514100Z",
     "start_time": "2024-09-18T10:42:42.733175200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9,)]\n"
     ]
    }
   ],
   "source": [
    "result = await db_connector[\"query_database\"](\n",
    "    kernel, sql_exp=\"SELECT COUNT(*) as count FROM Courses WHERE instructor = 'Alice'\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1832587b468749",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3.3 Function Parameter Annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93508834ba408843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:42:44.131216Z",
     "start_time": "2024-09-18T10:42:44.109463500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "class DBConnector:\n",
    "    def __init__(self, db_cursor):\n",
    "        self.db_cursor = db_cursor\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"数据库查询\",  # function 描述\n",
    "        name=\"query_database\"  # function 名字\n",
    "    )\n",
    "    def query(\n",
    "        self,\n",
    "        sql_exp: Annotated[str, \"SQL查询表达式\"]\n",
    "    ) -> Annotated[str, \"数据库查询结果\"]:\n",
    "        records = self.db_cursor.execute(sql_exp)\n",
    "        return records.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab230bbd4ffdd484",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3.4 Predefined functions in Semantic Kernel\n",
    "\n",
    "The method to load them:\n",
    "\n",
    "```python\n",
    "from semantic_kernel.core_plugins import <PluginName>\n",
    "```\n",
    "\n",
    "These plugins are:\n",
    "\n",
    "- [`ConversationSummaryPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/conversation_summary_plugin.py) - Generates a summary of a conversation.\n",
    "- [`HttpPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/http_plugin.py) - Sends HTTP requests, supporting GET, POST, PUT, and DELETE methods.\n",
    "- [`MathPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/math_plugin.py) - Performs addition and subtraction operations.\n",
    "- [`TextMemoryPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/text_memory_plugin.py) - Saves text into memory, enabling vector search functionality.\n",
    "- [`TextPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/text_plugin.py) - Converts text to uppercase or lowercase and trims leading/trailing spaces.\n",
    "- [`TimePlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/time_plugin.py) - Retrieves the current time and formats time parameters in various ways.\n",
    "- [`WaitPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/wait_plugin.py) - Waits for a specified amount of time.\n",
    "- [`WebSearchEnginePlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/web_search_engine_plugin.py) - Searches the internet for the provided text.\n",
    "\n",
    "--- \n",
    "\n",
    "This list shows built-in plugins in SK that can help in different tasks, from HTTP requests to text transformations and time management. Each plugin can be easily imported and used within the Semantic Kernel environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34d0fd41b46a0d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 4. Nested function calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47ee7b4b4742c8b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4.1 Nested function calls of Semantic Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99f7c5b04bc748ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:42:48.331942100Z",
     "start_time": "2024-09-18T10:42:48.315096Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "translate_prompt = \"\"\"\n",
    "将中文词'{{$chinese}}'翻译为日语\n",
    "直接给出一个翻译结果，不要评论。\n",
    "尽可能用Hanji表示。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a34e8ff67186f57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:42:49.986745800Z",
     "start_time": "2024-09-18T10:42:49.971286700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "joke_prompt = \"\"\"\n",
    "'{{$input}}'的日语是：{{MyDemoPlugin.translate $input}}\n",
    "根据以上词汇在中日文中的语义差异，讲一个笑话。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bf83b649d776210",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:42:50.891865100Z",
     "start_time": "2024-09-18T10:42:50.824847100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "# 加载 .env 到环境变量\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_=load_dotenv(find_dotenv())\n",
    "\n",
    "# 创建 semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# 配置OpenAi 服务。 OPENAI_BASE_URL 会被自动加载生效\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "service_id = \"default\"\n",
    "\n",
    "# 将 LLM 服务添加到 kernel 中\n",
    "kernel.add_service(\n",
    "    OpenAIChatCompletion(\n",
    "        service_id=service_id,\n",
    "        ai_model_id=\"gpt-3.5-turbo-1106\",\n",
    "        api_key=api_key\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "610e7495a6a1380d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:42:52.435654Z",
     "start_time": "2024-09-18T10:42:52.420611500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template.prompt_template_config import PromptTemplateConfig\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "req_settings = kernel.get_service(service_id).get_prompt_execution_settings_class()(service_id=service_id)\n",
    "\n",
    "trans_prompt_template_config = PromptTemplateConfig(\n",
    "    template=translate_prompt,\n",
    "    description=\"Translate Chinese to Japanese\",\n",
    "    execution_settings={service_id:req_settings},\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"chinese\", description=\"The source\", is_required=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "joke_prompt_template_config = PromptTemplateConfig(\n",
    "    template=joke_prompt,\n",
    "    description=\"Generate a joke about a specific topic\",\n",
    "    execution_settings={service_id:req_settings},\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The topic\", is_required=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "translate_function = kernel.add_function(\n",
    "    function_name=\"translate\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=trans_prompt_template_config,\n",
    ")\n",
    "\n",
    "joke_function = kernel.add_function(\n",
    "    function_name=\"joke\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=joke_prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccb0c64bd9fef6fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:43:02.104894100Z",
     "start_time": "2024-09-18T10:42:53.904391500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为了给日本朋友寄信，我学了很多日语词汇。但是当我寄出了一封“手紙”后，他却收到了一封真正的手纸！看来我还需要再多学习一下日语的语义差异啊！\n"
     ]
    }
   ],
   "source": [
    "result = await kernel.invoke(\n",
    "    joke_function,\n",
    "    KernelArguments(\n",
    "        input=\"信件\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0c24ba8b08aaf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4.2 Prompt template call Native Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12f4bfa0598b1ea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:43:11.005087500Z",
     "start_time": "2024-09-18T10:43:10.978402800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "已知，数据库形式为\n",
    "CREATE TABLE Courses (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    course_date DATE NOT NULL,\n",
    "    start_time TIME NOT NULL,\n",
    "    end_time TIME NOT NULL,\n",
    "    course_name VARCHAR(255) NOT NULL,\n",
    "    instructor VARCHAR(255) NOT NULL\n",
    ");\n",
    "\n",
    "用自然语言解释用户的SQL查询的意图和查询结果\n",
    "\n",
    "用户输入：{{$input}}\n",
    "\n",
    "查询结果：{{DBConnectorPlugin.query_database $input}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1bba0f3a2223eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:43:12.326141700Z",
     "start_time": "2024-09-18T10:43:12.308347900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# load native function\n",
    "kernel.add_plugin(DBConnectorPlugin(cursor), \"DBConnectorPlugin\")\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    description=\"查询数据库\",\n",
    "    execution_setting={service_id:reg_settings},\n",
    "    input_variable=[\n",
    "        InputVariable(name=\"input\",decription=\"The user query\", is_required=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "db_query_function = kernel.add_function(\n",
    "    function_name=\"db_query\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d110cbf05b5bb89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:43:17.742143700Z",
     "start_time": "2024-09-18T10:43:13.614439700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户的SQL查询意图是要统计出所有由Eric教授的课程的数量。查询结果显示没有由Eric教授的课程，因为返回的结果是0。\n"
     ]
    }
   ],
   "source": [
    "result = await kernel.invoke(\n",
    "    db_query_function,\n",
    "    KernelArguments(\n",
    "        input=\"SELECT COUNT(*) as count FROM Courses WHERE instructor = 'Eric'\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f42a34e77040ae",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 5. Memory\n",
    "Using the memory in SK is very simple:\n",
    "1. Use kernel.add_service() to add a large text vector generation service.\n",
    "2. Use kernel.add_plugin() to add a connection to a vector database.\n",
    "3. Use memory.save_information() to save information to the memory store.\n",
    "4. Use memory.search() to search for information.\n",
    "\n",
    "Using the README.md data from ChatALL, using memory as the memory store, we do not base conversations on documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac959950408b8a6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5.1 Initiate Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3883503e7d1ec5e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:43:17.851466500Z",
     "start_time": "2024-09-18T10:43:17.746191200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "import os\n",
    "\n",
    "# Load .env into environment variables\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Create the semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Configure the OpenAI service. OPENAI_BASE_URL will be automatically loaded and take effect\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "service_id = \"default\"\n",
    "\n",
    "llm_service =  OpenAIChatCompletion(\n",
    "        service_id=service_id,\n",
    "        ai_model_id=\"gpt-3.5-turbo-1106\",\n",
    "        api_key=api_key\n",
    "    )\n",
    "\n",
    "# Add the LLM service to the kernel\n",
    "kernel.add_service(llm_service)\n",
    "\n",
    "embedding_gen = OpenAITextEmbedding(\n",
    "    ai_model_id=\"text-embedding-ada-002\",\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# Add the Embedding service to the kernel\n",
    "kernel.add_service(embedding_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65ce05687c0c1053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:43:19.120142700Z",
     "start_time": "2024-09-18T10:43:19.062845100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='TestMemoryPlugin', description=None, functions={'recall': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='recall', plugin_name='TestMemoryPlugin', description='Recall a fact from the long term memory', parameters=[KernelParameterMetadata(name='ask', description='The information to retrieve', default_value=None, type_='str', is_required=True, type_object=<class 'str'>), KernelParameterMetadata(name='collection', description='The collection to search for information.', default_value='generic', type_='str', is_required=False, type_object=<class 'str'>), KernelParameterMetadata(name='relevance', description='The relevance score, from 0.0 to 1.0; 1.0 means perfect match', default_value=0.75, type_='float', is_required=False, type_object=<class 'float'>), KernelParameterMetadata(name='limit', description='The maximum number of relevant memories to recall.', default_value=1, type_='int', is_required=False, type_object=<class 'int'>)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=None)), method=<bound method TextMemoryPlugin.recall of TextMemoryPlugin(memory=SemanticTextMemory())>, stream_method=None), 'save': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='save', plugin_name='TestMemoryPlugin', description='Save information to semantic memory', parameters=[KernelParameterMetadata(name='text', description='The information to save.', default_value=None, type_='str', is_required=True, type_object=<class 'str'>), KernelParameterMetadata(name='key', description='The unique key to associate with the information.', default_value=None, type_='str', is_required=True, type_object=<class 'str'>), KernelParameterMetadata(name='collection', description='The collection to save the information.', default_value='generic', type_='str', is_required=False, type_object=<class 'str'>)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='', is_required=True, type_object=None)), method=<bound method TextMemoryPlugin.save of TextMemoryPlugin(memory=SemanticTextMemory())>, stream_method=None)})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.memory.volatile_memory_store import VolatileMemoryStore\n",
    "\n",
    "# Create a (memory) vector database\n",
    "memory = SemanticTextMemory(storage=VolatileMemoryStore(), embeddings_generator=embedding_gen)\n",
    "\n",
    "# Add a plugin that connects to the vector database\n",
    "kernel.add_plugin(TextMemoryPlugin(memory), \"TestMemoryPlugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e163580af8210e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5.2  Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe02d7fbd3070eac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:43:53.549379Z",
     "start_time": "2024-09-18T10:43:21.969517500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from semantic_kernel.text import split_markdown_lines\n",
    "\n",
    "# Read the file content\n",
    "with open('data/ChatALL.md', 'r') as f:\n",
    "    # with open('sk_samples/SamplePlugin/SamplePlugin.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Split the file content into chunks, with a maximum of 100 tokens per chunk (Note: SK’s text split functionality currently supports Chinese less well compared to English)\n",
    "lines = split_markdown_lines(content, 100)\n",
    "\n",
    "collection_id = \"generic\"\n",
    "\n",
    "# Store the chunked content into memory\n",
    "for index, line in enumerate(lines):\n",
    "    await memory.save_information(collection_id, id=index, text=line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81616544994c15a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5.3 Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "258ae21294309cd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:43:58.201616Z",
     "start_time": "2024-09-18T10:43:57.566124100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "拥有可以访问这些 AI 的帐号，或 API token。\n",
      "2. 与 AI 网站有可靠的网络连接。\n",
      "\n",
      "## 下载 / 安装\n",
      "\n",
      "从 https://github.com/sunner/ChatALL/releases 下载\n",
      "\n",
      "### Windows 系统\n",
      "\n",
      "直接下载 \\*-win.exe 安装文件并运行之。\n",
      "\n",
      "### macOS 系统\n",
      "\n",
      "对于苹果硅芯片 Mac（M1，M2 CPU），请下载 \\*-mac-arm64.\n"
     ]
    }
   ],
   "source": [
    "result = await memory.search(collection_id, \"ChatALL 怎么下载\")\n",
    "print(result[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265588e443eca7d9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5.4 Use nested functions to build a simple RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aba040f904dfd3e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T10:44:04.524283200Z",
     "start_time": "2024-09-18T10:44:01.391031100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 https://github.com/sunner/ChatALL/releases 下载安装文件。对于Windows系统，下载\\*-win.exe文件并运行；对于macOS系统，苹果硅芯片Mac（M1，M2 CPU）下载\\*-mac-arm64文件。\n"
     ]
    }
   ],
   "source": [
    "# Create a semantic function directly in the code. This is not recommended in real projects.\n",
    "# It calls `recall()` inside.\n",
    "prompt = \"\"\"\n",
    "基于下面的背景信息回答问题。如果背景信息为空，或者和问题不相关，请回答\"我不知道\"。\n",
    "\n",
    "[背景信息开始]\n",
    "{{recall $input}}\n",
    "[背景信息结束]\n",
    "\n",
    "问题：{{$input}}\n",
    "回答：\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "reg_settings = kernel.get_service(service_id).get_prompt_execution_settings_class()(service_id=service_id)\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    description=\"RAG回答\",\n",
    "    execution_settings={service_id:reg_settings},\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The user query\", is_requied=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "reg_function = kernel.add_function(\n",
    "    function_name=\"search_and_answer\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")\n",
    "\n",
    "result = await kernel.invoke(\n",
    "    reg_function,\n",
    "    KernelArguments(input=\"ChatALL 怎么下载\")\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ef43dd05fcb45",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5.5. Connecting to Other VectorDBs\n",
    "Semantic Kernel is currently adapted to many mainstream vector databases.\n",
    "For details, refer to:  https://learn.microsoft.com/en-us/semantic-kernel/memories/vector-db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b69ad1d4ea6e4df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 6. Planner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7675d3fc-553d-405b-9acd-99accfc3b2a5",
   "metadata": {},
   "source": [
    "## 6.1 Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20426c2d2a934154",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Agent-Overview:\n",
    "\n",
    "<img src=\"data/agent-overview.png\" style=\"margin-left: 0px\" width=700px>\n",
    "\n",
    "#### The Differences Between an Agent, RAG, and Copilot : \n",
    "\n",
    "<img src=\"data/agent_2.png\" style=\"margin-left: 0px\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e74560-b3a6-4c32-ba8b-80ac509ddc00",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 6.2. SK Python provides four types of Planners:\n",
    "\n",
    "**SequentialPlanner**  \n",
    "Creates a plan consisting of a series of steps, where each step is interconnected through custom-generated input and output variables.  \n",
    "Core: [https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/sequential_planner/Plugins/SequentialPlanning/skprompt.txt](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/sequential_planner/Plugins/SequentialPlanning/skprompt.txt)  \n",
    "Official Example: [https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/sequential_planner.py](https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/sequential_planner.py)\n",
    "\n",
    "**ActionPlanner**  \n",
    "Similar to OpenAI Function Calling, it finds a function to execute from all the registered plugins in the kernel.  \n",
    "Core prompt: [https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/action_planner/skprompt.txt](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/action_planner/skprompt.txt)  \n",
    "Official Example: [https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/action_planner.py](https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/action_planner.py)\n",
    "\n",
    "**StepwisePlanner**  \n",
    "After executing each step, it performs a review.  \n",
    "It only outputs actions without executing them.  \n",
    "Core prompt: [https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/stepwise_planner/Plugins/StepwiseStep/skprompt.txt](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/stepwise_planner/Plugins/StepwiseStep/skprompt.txt)\n",
    "\n",
    "**BasicPlanner**  \n",
    "Not recommended for use. It breaks tasks down and automatically calls various functions to complete them. It is mainly for basic validation and will eventually be replaced by SequentialPlanner.  \n",
    "Core prompt: [https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/basic_planner.py#L27-L123](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/basic_planner.py#L27-L123)\n",
    "\n",
    "The steps to use a planner are very simple:\n",
    "\n",
    "1. Register the plugin to the kernel.\n",
    "2. Instantiate a planner using the kernel as a parameter.\n",
    "3. Call the planner's `create_plan_async()` method to obtain a plan.\n",
    "4. Call the plan's `invoke_async()` method to execute the plan.  \n",
    "(Note: The interfaces of different planners are not consistent, so they cannot be used interchangeably.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4e503-b105-4273-abb2-922da7eb1eb0",
   "metadata": {},
   "source": [
    "## 6.3 Implement an Agent\n",
    "To implement an Agent that can use both search and calendar tools through a Planner, follow these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd69512e-7056-4629-aa24-ee44566b7e94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T15:34:45.166038Z",
     "start_time": "2024-09-19T15:34:45.106809100Z"
    }
   },
   "outputs": [],
   "source": [
    "from semantic_kernel.core_plugins import WebSearchEnginePlugin\n",
    "from semantic_kernel.connectors.search_engine import  BingConnector\n",
    "from semantic_kernel.planners import SequentialPlanner\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "import os\n",
    "\n",
    "# Load .env into environment variables\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Create the semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Configure the OpenAI service. OPENAI_BASE_URL will be automatically loaded and take effect\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "service_id = \"default\"\n",
    "\n",
    "llm_service =  OpenAIChatCompletion(\n",
    "        service_id=service_id,\n",
    "        # ai_model_id=\"gpt-3.5-turbo-1106\",\n",
    "        ai_model_id=\"gpt-4\",\n",
    "        api_key=api_key\n",
    "    )\n",
    "\n",
    "# Add the LLM service to the kernel\n",
    "kernel.add_service(llm_service)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a523130b14618",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "how to register BING API KEY ：[BING API KEY](https://portal.azure.com/#view/Microsoft_Azure_Marketplace/MarketplaceOffersBlade/selectedMenuItemId/home)  --- search with \" Bing Custom Search\" --- Create a Bing custom search resource and get API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ab61cb37f1c0f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T15:34:47.251760700Z",
     "start_time": "2024-09-19T15:34:47.233988900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='WebSearch', description=None, functions={'search': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='search', plugin_name='WebSearch', description='Performs a web search for a given query', parameters=[KernelParameterMetadata(name='query', description='The search query', default_value=None, type_='str', is_required=True, type_object=<class 'str'>), KernelParameterMetadata(name='num_results', description='The number of search results to return', default_value=1, type_='int', is_required=False, type_object=<class 'int'>), KernelParameterMetadata(name='offset', description='The number of search results to skip', default_value=0, type_='int', is_required=False, type_object=<class 'int'>)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=None)), method=<bound method WebSearchEnginePlugin.search of <semantic_kernel.core_plugins.web_search_engine_plugin.WebSearchEnginePlugin object at 0x0000019F7D140DF0>>, stream_method=None)})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import search plugin\n",
    "connector = BingConnector(api_key=os.getenv(\"BING_API_KEY\"))\n",
    "kernel.add_plugin(WebSearchEnginePlugin(connector),\"WebSearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddaefd4ebb7487e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:54:29.356228100Z",
     "start_time": "2024-09-19T16:54:29.332169500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from semantic_kernel.core_plugins import MathPlugin, TextPlugin, TimePlugin\n",
    "\n",
    "kernel.add_plugin(TimePlugin(),\"time\")\n",
    "\n",
    "# create planner\n",
    "planner = SequentialPlanner(kernel, service_id)\n",
    "\n",
    "# begin\n",
    "# query = \"On which date was OpenAI o1 released?\"\n",
    "query = \"\"\"On which date was OpenAI o1 released?\"\"\"\n",
    "\n",
    "plan = await planner.create_plan(goal=query)\n",
    "result = await plan.invoke(kernel)\n",
    "\n",
    "for i,step in enumerate(plan._steps):\n",
    "    print(step.description)\n",
    "    print(step.plugin_name + \".\" + step.name, end=\": \")\n",
    "    print(step.parameters)\n",
    "    print(step._outputs[0] + \"=\" + str(result.metadata[\"results\"][i].value))\n",
    "\n",
    "print(f\"Agent 回复: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14302ab94b5e92e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 7. VS Code Plugin\n",
    "\n",
    "This is a VS Code plugin that allows you to directly create and debug Semantic Functions within VS Code.\n",
    "\n",
    "Installation link: [https://marketplace.visualstudio.com/items?itemName=ms-semantic-kernel.semantic-kernel](https://marketplace.visualstudio.com/items?itemName=ms-semantic-kernel.semantic-kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c7f89-0b1d-4cc6-845c-88fed7e7a80f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "1. Should I use a development framework?\n",
    "2. When should I choose SK?\n",
    "\n",
    "- If you frequently need to switch between different LLMs or have extensive prompt debugging needs, choosing a development framework will make your life easier.\n",
    "- If your prompt contains a lot of nested calls.\n",
    "- If you must use the C#/JAVA technology stack, SK might be your only option for now.\n",
    "- If you're using the Python technology stack, you might want to compare it with LangChain before making a decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d09b23-4626-4b3e-aec8-da8a23d05330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sk_env)",
   "language": "python",
   "name": "sk_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
